package com.davidstudioz.david.models

import android.app.ActivityManager
import android.content.Context
import android.util.Log
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.Job
import kotlinx.coroutines.withContext
import okhttp3.OkHttpClient
import okhttp3.Request
import java.io.File
import java.io.FileOutputStream
import java.io.RandomAccessFile
import java.util.concurrent.TimeUnit

data class AIModel(
    val name: String,
    val url: String,
    val size: String,
    val minRamGB: Int,
    val type: String, // "LLM", "Vision", "Speech", "Language", "Gesture"
    val format: String = "GGUF", // "GGUF", "ONNX", "TFLite", "GGML"
    val language: String = "en", // Language code for language models
    val description: String = "" // User-friendly description
)

/**
 * Download progress state for UI updates
 */
data class DownloadProgress(
    val modelName: String,
    val progress: Int, // 0-100
    val downloadedMB: Float,
    val totalMB: Float,
    val status: DownloadStatus,
    val error: String? = null,
    val canResume: Boolean = false
)

enum class DownloadStatus {
    QUEUED,
    DOWNLOADING,
    PAUSED,
    COMPLETED,
    FAILED,
    CANCELLED
}

/**
 * ModelManager - COMPREHENSIVE FIX with Pause/Resume
 * âœ… FIXED: Download validation and verification
 * âœ… FIXED: Pause/Resume download support
 * âœ… FIXED: Proper model loading checks
 * âœ… FIXED: Language model duplicate detection
 * âœ… FIXED: Model status reporting
 */
class ModelManager(private val context: Context) {
    
    private val httpClient = OkHttpClient.Builder()
        .connectTimeout(60, TimeUnit.SECONDS)
        .readTimeout(300, TimeUnit.SECONDS)
        .writeTimeout(300, TimeUnit.SECONDS)
        .followRedirects(true)
        .followSslRedirects(true)
        .retryOnConnectionFailure(true)
        .build()
        
    private val modelsDir = File(context.filesDir, "david_models")
    private val tempDir = File(context.cacheDir, "model_downloads")
    
    // Download state tracking for UI
    private val activeDownloads = mutableMapOf<String, Job>()
    private val downloadProgress = mutableMapOf<String, DownloadProgress>()
    private val pausedDownloads = mutableMapOf<String, Long>() // Model name -> downloaded bytes
    
    init {
        try {
            if (!modelsDir.exists()) {
                modelsDir.mkdirs()
                Log.d(TAG, "Created models directory: ${modelsDir.absolutePath}")
            }
            if (!tempDir.exists()) {
                tempDir.mkdirs()
                Log.d(TAG, "Created temp directory: ${tempDir.absolutePath}")
            }
        } catch (e: Exception) {
            Log.e(TAG, "Error creating directories", e)
        }
    }
    
    /**
     * Get device RAM in GB
     */
    fun getDeviceRamGB(): Int {
        return try {
            val activityManager = context.getSystemService(Context.ACTIVITY_SERVICE) as ActivityManager
            val memInfo = ActivityManager.MemoryInfo()
            activityManager.getMemoryInfo(memInfo)
            val ramGB = (memInfo.totalMem / (1024 * 1024 * 1024)).toInt()
            Log.d(TAG, "Device RAM: $ramGB GB")
            ramGB
        } catch (e: Exception) {
            Log.e(TAG, "Error getting device RAM", e)
            2 // Default to 2GB for safety
        }
    }
    
    /**
     * Get essential models to download based on device capacity
     */
    fun getEssentialModels(): List<AIModel> {
        val deviceRam = getDeviceRamGB()
        val models = mutableListOf<AIModel>()
        
        // Voice model (always needed)
        models.add(when {
            deviceRam >= 3 -> getVoiceModel("small")!!
            deviceRam >= 2 -> getVoiceModel("base")!!
            else -> getVoiceModel("tiny")!!
        })
        
        // LLM model for chat
        models.add(when {
            deviceRam >= 4 -> getLLMModel("pro")!!
            deviceRam >= 3 -> getLLMModel("standard")!!
            else -> getLLMModel("light")!!
        })
        
        // Vision model
        models.add(if (deviceRam >= 2) getVisionModel("standard")!! else getVisionModel("lite")!!)
        
        // Gesture models (both needed)
        models.addAll(getGestureModels())
        
        // Multilingual model (works for ALL 15 languages!)
        models.add(getMultilingualModel())
        
        Log.d(TAG, "Essential models for ${deviceRam}GB RAM: ${models.size} models")
        return models
    }
    
    /**
     * REAL VOICE MODELS - Whisper from HuggingFace
     */
    private fun getVoiceModel(variant: String): AIModel? {
        return when (variant.lowercase()) {
            "tiny" -> AIModel(
                "D.A.V.I.D Voice Tiny",
                "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-tiny.en.bin",
                "75 MB", 1, "Speech", "GGML", "en",
                "Fastest voice recognition, good for low-end devices"
            )
            "base" -> AIModel(
                "D.A.V.I.D Voice Base",
                "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.en.bin",
                "142 MB", 2, "Speech", "GGML", "en",
                "Balanced voice recognition for most devices"
            )
            "small" -> AIModel(
                "D.A.V.I.D Voice Pro",
                "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-small.en.bin",
                "466 MB", 3, "Speech", "GGML", "en",
                "High-accuracy voice recognition for powerful devices"
            )
            else -> null
        }
    }
    
    /**
     * REAL LLM MODELS - TinyLlama, Qwen, Phi-2 from HuggingFace
     */
    private fun getLLMModel(variant: String): AIModel? {
        return when (variant.lowercase()) {
            "light" -> AIModel(
                "D.A.V.I.D Chat Light",
                "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
                "669 MB", 2, "LLM", "GGUF", "en",
                "Lightweight AI chat for 2GB+ devices"
            )
            "standard" -> AIModel(
                "D.A.V.I.D Chat Standard",
                "https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat-GGUF/resolve/main/qwen1_5-1_8b-chat-q4_k_m.gguf",
                "1.1 GB", 3, "LLM", "GGUF", "en",
                "Balanced AI chat for 3GB+ devices"
            )
            "pro" -> AIModel(
                "D.A.V.I.D Chat Pro",
                "https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q4_K_M.gguf",
                "1.6 GB", 4, "LLM", "GGUF", "en",
                "Advanced AI chat for 4GB+ devices"
            )
            else -> null
        }
    }
    
    /**
     * REAL VISION MODELS - ONNX from official repository
     */
    private fun getVisionModel(variant: String): AIModel? {
        return when (variant.lowercase()) {
            "lite" -> AIModel(
                "D.A.V.I.D Vision Lite",
                "https://github.com/onnx/models/raw/main/validated/vision/classification/mobilenet/model/mobilenetv2-12.onnx",
                "14 MB", 1, "Vision", "ONNX", "en",
                "Basic image recognition for all devices"
            )
            "standard" -> AIModel(
                "D.A.V.I.D Vision Standard",
                "https://github.com/onnx/models/raw/main/validated/vision/classification/resnet/model/resnet50-v2-7.onnx",
                "98 MB", 2, "Vision", "ONNX", "en",
                "Advanced image recognition for 2GB+ devices"
            )
            else -> null
        }
    }
    
    /**
     * REAL GESTURE MODELS - MediaPipe from Google
     */
    fun getGestureModels(): List<AIModel> {
        return listOf(
            AIModel(
                "D.A.V.I.D Gesture Hand",
                "https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/latest/hand_landmarker.task",
                "25 MB", 1, "Gesture", "TFLite", "en",
                "Hand detection and 21-point tracking"
            ),
            AIModel(
                "D.A.V.I.D Gesture Recognition",
                "https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/latest/gesture_recognizer.task",
                "31 MB", 1, "Gesture", "TFLite", "en",
                "Gesture classification (thumbs up, peace, etc.)"
            )
        )
    }
    
    /**
     * MULTILINGUAL MODEL - Single model for ALL 15 languages
     */
    private fun getMultilingualModel(): AIModel {
        return AIModel(
            "D.A.V.I.D Multilingual",
            "https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/onnx/model.onnx",
            "120 MB", 1, "Language", "ONNX", "multilingual",
            "Supports all 15 languages (English + 14 Indian languages)"
        )
    }
    
    /**
     * ALL INDIAN LANGUAGES + ENGLISH (15 Total)
     */
    fun getAllLanguages(): List<String> {
        return listOf(
            "English", "Hindi", "Tamil", "Telugu", "Bengali",
            "Marathi", "Gujarati", "Kannada", "Malayalam", "Punjabi",
            "Odia", "Urdu", "Sanskrit", "Kashmiri", "Assamese"
        )
    }
    
    /**
     * FIXED: Check if language model is downloaded (multilingual model works for all)
     */
    fun isLanguageModelDownloaded(language: String): Boolean {
        val multilingualModel = getDownloadedModels().firstOrNull { 
            it.name.contains("language", ignoreCase = true) || 
            it.name.contains("multilingual", ignoreCase = true)
        }
        
        if (multilingualModel != null && multilingualModel.exists() && multilingualModel.length() > 1024 * 1024) {
            Log.d(TAG, "Language model found for $language: ${multilingualModel.name}")
            return true
        }
        
        Log.d(TAG, "Language model NOT found for $language")
        return false
    }
    
    /**
     * NEW: Download model with pause/resume support
     */
    suspend fun downloadModel(
        model: AIModel,
        onProgress: (DownloadProgress) -> Unit = {}
    ): Result<File> = withContext(Dispatchers.IO) {
        try {
            Log.d(TAG, "ðŸ“¥ Downloading: ${model.name} from ${model.url}")
            
            val fileName = "${model.type.lowercase()}_${model.language}_${System.currentTimeMillis()}.${model.format.lowercase()}"
            val modelFile = File(modelsDir, fileName)
            val tempFile = File(tempDir, "$fileName.tmp")
            
            // Check if similar model already exists and is valid
            val existingModel = getDownloadedModels().firstOrNull {
                it.name.contains(model.type.lowercase(), ignoreCase = true) && 
                (it.name.contains(model.language, ignoreCase = true) || model.language == "multilingual") &&
                isModelValid(it)
            }
            
            if (existingModel != null) {
                Log.d(TAG, "âœ… Model already exists: ${model.name}")
                val completeProgress = DownloadProgress(
                    model.name, 100, parseSizeMB(model.size), parseSizeMB(model.size), 
                    DownloadStatus.COMPLETED, canResume = false
                )
                withContext(Dispatchers.Main) { onProgress(completeProgress) }
                return@withContext Result.success(existingModel)
            }
            
            // Check for paused download
            val startByte = if (tempFile.exists()) tempFile.length() else 0L
            val canResume = startByte > 0
            
            // Initial progress
            val initialProgress = DownloadProgress(
                model.name, 0, 0f, parseSizeMB(model.size), 
                DownloadStatus.QUEUED, canResume = canResume
            )
            downloadProgress[model.name] = initialProgress
            withContext(Dispatchers.Main) { onProgress(initialProgress) }
            
            // Build request with resume support
            val requestBuilder = Request.Builder()
                .url(model.url)
                .header("User-Agent", "Mozilla/5.0 (Linux; Android 14) AppleWebKit/537.36")
            
            if (canResume) {
                requestBuilder.header("Range", "bytes=$startByte-")
                Log.d(TAG, "Resuming download from byte $startByte")
            }
            
            val request = requestBuilder.build()
            
            // Update to downloading status
            val downloadingProgress = initialProgress.copy(status = DownloadStatus.DOWNLOADING)
            downloadProgress[model.name] = downloadingProgress
            withContext(Dispatchers.Main) { onProgress(downloadingProgress) }
            
            val response = httpClient.newCall(request).execute()
            
            if (!response.isSuccessful && response.code != 206) { // 206 = Partial Content
                throw Exception("HTTP ${response.code}: ${response.message}")
            }
            
            val body = response.body ?: throw Exception("Empty response body")
            val contentLength = body.contentLength()
            val totalLength = if (canResume) startByte + contentLength else contentLength
            val totalMB = totalLength / (1024f * 1024f)
            
            // Open file for writing (append if resuming)
            RandomAccessFile(tempFile, "rw").use { output ->
                if (canResume) {
                    output.seek(startByte)
                }
                
                body.byteStream().use { input ->
                    val buffer = ByteArray(8192)
                    var downloaded = startByte
                    var read: Int
                    var lastProgressUpdate = 0
                    
                    while (input.read(buffer).also { read = it } != -1) {
                        // Check if download is paused
                        if (downloadProgress[model.name]?.status == DownloadStatus.PAUSED) {
                            pausedDownloads[model.name] = downloaded
                            Log.d(TAG, "Download paused: ${model.name} at $downloaded bytes")
                            return@withContext Result.failure(Exception("Download paused"))
                        }
                        
                        output.write(buffer, 0, read)
                        downloaded += read
                        
                        if (totalLength > 0) {
                            val progress = ((downloaded * 100) / totalLength).toInt()
                            
                            // Update UI every 1% or at completion
                            if (progress > lastProgressUpdate || progress == 100) {
                                lastProgressUpdate = progress
                                val downloadedMB = downloaded / (1024f * 1024f)
                                
                                val progressUpdate = DownloadProgress(
                                    model.name, progress, downloadedMB, totalMB, 
                                    DownloadStatus.DOWNLOADING, canResume = true
                                )
                                downloadProgress[model.name] = progressUpdate
                                
                                withContext(Dispatchers.Main) {
                                    onProgress(progressUpdate)
                                }
                            }
                        }
                    }
                }
            }
            
            // Move temp file to final location
            if (tempFile.renameTo(modelFile)) {
                tempFile.delete() // Clean up if rename succeeded
            } else {
                // Fallback: copy file
                tempFile.copyTo(modelFile, overwrite = true)
                tempFile.delete()
            }
            
            // Verify downloaded file
            if (!isModelValid(modelFile)) {
                throw Exception("Downloaded model file is invalid or corrupted")
            }
            
            // Completion
            val completeProgress = DownloadProgress(
                model.name, 100, totalMB, totalMB, DownloadStatus.COMPLETED, canResume = false
            )
            downloadProgress[model.name] = completeProgress
            withContext(Dispatchers.Main) { onProgress(completeProgress) }
            
            pausedDownloads.remove(model.name)
            
            Log.d(TAG, "âœ… Downloaded: ${model.name} â†’ ${modelFile.absolutePath} (${modelFile.length() / (1024 * 1024)}MB)")
            Result.success(modelFile)
            
        } catch (e: Exception) {
            Log.e(TAG, "âŒ Download failed: ${model.name}", e)
            
            val failedProgress = DownloadProgress(
                model.name, 0, 0f, parseSizeMB(model.size), 
                DownloadStatus.FAILED, e.message, canResume = true
            )
            downloadProgress[model.name] = failedProgress
            withContext(Dispatchers.Main) { onProgress(failedProgress) }
            
            Result.failure(e)
        }
    }
    
    /**
     * NEW: Pause active download
     */
    fun pauseDownload(modelName: String) {
        downloadProgress[modelName] = downloadProgress[modelName]?.copy(
            status = DownloadStatus.PAUSED
        ) ?: return
        Log.d(TAG, "Pausing download: $modelName")
    }
    
    /**
     * NEW: Resume paused download
     */
    suspend fun resumeDownload(
        model: AIModel,
        onProgress: (DownloadProgress) -> Unit = {}
    ): Result<File> {
        Log.d(TAG, "Resuming download: ${model.name}")
        return downloadModel(model, onProgress)
    }
    
    /**
     * NEW: Validate model file
     */
    private fun isModelValid(file: File): Boolean {
        return try {
            file.exists() && file.isFile && file.length() > 1024 * 1024 && file.canRead()
        } catch (e: Exception) {
            false
        }
    }
    
    /**
     * Get download progress for a model
     */
    fun getDownloadProgress(modelName: String): DownloadProgress? {
        return downloadProgress[modelName]
    }
    
    /**
     * Cancel active download
     */
    fun cancelDownload(modelName: String) {
        activeDownloads[modelName]?.cancel()
        activeDownloads.remove(modelName)
        pausedDownloads.remove(modelName)
        
        downloadProgress[modelName] = downloadProgress[modelName]?.copy(
            status = DownloadStatus.CANCELLED
        ) ?: return
        
        // Clean up temp file
        try {
            tempDir.listFiles()?.forEach { tempFile ->
                if (tempFile.name.contains(modelName.take(20))) {
                    tempFile.delete()
                }
            }
        } catch (e: Exception) {
            Log.e(TAG, "Error cleaning temp files", e)
        }
    }
    
    /**
     * Parse size string to MB
     */
    private fun parseSizeMB(size: String): Float {
        val num = size.replace("[^0-9.]".toRegex(), "").toFloatOrNull() ?: 0f
        return when {
            size.contains("GB", ignoreCase = true) -> num * 1024f
            size.contains("MB", ignoreCase = true) -> num
            else -> num
        }
    }
    
    /**
     * Check if essential models are downloaded
     */
    fun areEssentialModelsDownloaded(): Boolean {
        val essential = getEssentialModels()
        val downloaded = getDownloadedModels().filter { isModelValid(it) }
        
        // Check each essential model type
        val hasLLM = downloaded.any { it.name.contains("llm", ignoreCase = true) }
        val hasVoice = downloaded.any { it.name.contains("speech", ignoreCase = true) }
        val hasVision = downloaded.any { it.name.contains("vision", ignoreCase = true) }
        val hasGesture = downloaded.any { it.name.contains("gesture", ignoreCase = true) }
        val hasLanguage = downloaded.any { 
            it.name.contains("language", ignoreCase = true) || 
            it.name.contains("multilingual", ignoreCase = true)
        }
        
        return hasLLM && hasVoice && hasVision && hasGesture && hasLanguage
    }
    
    /**
     * Get list of downloaded model files
     */
    fun getDownloadedModels(): List<File> {
        return try {
            modelsDir.listFiles()?.filter { 
                it.isFile && isModelValid(it)
            }?.toList() ?: emptyList()
        } catch (e: Exception) {
            emptyList()
        }
    }
    
    /**
     * Get model path by type and language
     */
    fun getModelPath(type: String, language: String = "en"): File? {
        return getDownloadedModels().firstOrNull { 
            it.name.contains(type.lowercase(), ignoreCase = true) && 
            (it.name.contains(language, ignoreCase = true) || language == "multilingual") &&
            isModelValid(it)
        }
    }
    
    /**
     * Delete a specific model
     */
    fun deleteModel(file: File): Boolean {
        return try {
            file.delete()
            Log.d(TAG, "âœ… Deleted model: ${file.name}")
            true
        } catch (e: Exception) {
            Log.e(TAG, "Error deleting model: ${file.name}", e)
            false
        }
    }
    
    companion object {
        private const val TAG = "ModelManager"
    }
}